{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCOKPdZ8yeKv"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from category_encoders import OneHotEncoder, CatBoostEncoder, MEstimateEncoder\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
        "\n",
        "from sklearn import set_config\n",
        "import os\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import optuna\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.base import clone\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optuna\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Prameters for Reproduciblity\n",
        "pd.set_option(\"display.max_rows\",100)\n",
        "FILE_PATH = \"/content/playground-series-s4e2/\"\n",
        "TARGET = \"NObeyesdad\"\n",
        "n_splits = 10\n",
        "RANDOM_SEED = 43"
      ],
      "metadata": {
        "id": "f-hqFcTgz6t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all data\n",
        "train = pd.read_csv(os.path.join(FILE_PATH, \"train.csv\"))\n",
        "test = pd.read_csv(os.path.join(FILE_PATH, \"test.csv\"))\n",
        "sample_sub = pd.read_csv(os.path.join(FILE_PATH, \"sample_submission.csv\"))\n",
        "train_org = pd.read_csv(\"/content/obesity-or-cvd-risk-classifyregressorcluster/ObesityDataSet.csv\")"
      ],
      "metadata": {
        "id": "-xVqatl3TwKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettify_df(df):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = df.columns\n",
        "\n",
        "    for row in df.values:\n",
        "        table.add_row(row)\n",
        "    print(table)"
      ],
      "metadata": {
        "id": "BIHNBUR2T02Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "id": "DQ8fW7ljT27A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "print(\"Train Data\")\n",
        "print(f\"Total number of rows: {len(train)}\")\n",
        "print(f\"Total number of columns: {train.shape[1]}\\n\")\n",
        "\n",
        "# Test Data\n",
        "print(\"Test Data\")\n",
        "print(f\"Total number of rows: {len(test)}\")\n",
        "print(f\"Total number of columns:{test.shape[1]}\")"
      ],
      "metadata": {
        "id": "nASKMNlMT6Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check null and unique count\n",
        "# FHWO: family_history_with_overweight\n",
        "train_copy = train.rename(columns={\"family_history_with_overweight\":\"FHWO\"})\n",
        "tmp = pd.DataFrame(index=train_copy.columns)\n",
        "tmp['count'] = train_copy.count()\n",
        "tmp['dtype'] = train_copy.dtypes\n",
        "tmp['nunique'] = train_copy.nunique()\n",
        "tmp['%nunique'] = (tmp['nunique']/len(train_copy))*100\n",
        "tmp['%null'] = (train_copy.isnull().sum()/len(train_copy))*100\n",
        "tmp['min'] = train_copy.min()\n",
        "tmp['max'] = train_copy.max()\n",
        "tmp\n",
        "\n",
        "tmp.reset_index(inplace=True)\n",
        "tmp = tmp.rename(columns = {\"index\":\"Column Name\"})\n",
        "tmp = tmp.round(3)\n",
        "prettify_df(tmp)\n",
        "del tmp, train_copy"
      ],
      "metadata": {
        "id": "hw5U8kOkWXHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Distribution with Gender\n",
        "\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "tmp = pd.DataFrame(train.groupby([TARGET,'Gender'])[\"id\"].agg('count'))\n",
        "tmp.columns = ['Count']\n",
        "train[TARGET].value_counts()\n",
        "tmp = pd.merge(tmp,train[TARGET].value_counts(),left_index=True, right_index=True)\n",
        "tmp.columns = ['gender_count','target_class_count']\n",
        "tmp['%gender_count'] = tmp['gender_count']/tmp['target_class_count']\n",
        "tmp[\"%target_class_count\"] = tmp['target_class_count']/len(train)\n",
        "tmp = tmp[['gender_count','%gender_count','target_class_count','%target_class_count']]\n",
        "print(\"Target Distribution with Gender\")\n",
        "tmp"
      ],
      "metadata": {
        "id": "vYz1OQnnWcDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_num_cols = list(train.select_dtypes(\"float\").columns)\n",
        "raw_cat_cols = list(train.columns.drop(raw_num_cols+[TARGET]))\n",
        "\n",
        "full_form = dict({'FAVC' : \"Frequent consumption of high caloric food\",\n",
        "                  'FCVC' : \"Frequency of consumption of vegetables\",\n",
        "                  'NCP' :\"Number of main meal\",\n",
        "                  'CAEC': \"Consumption of food between meals\",\n",
        "                  'CH2O': \"Consumption of water daily\",\n",
        "                  'SCC':  \"Calories consumption monitoring\",\n",
        "                  'FAF': \"Physical activity frequency\",\n",
        "                  'TUE': \"Time using technology devices\",\n",
        "                  'CALC': \"Consumption of alcohol\" ,\n",
        "                  'MTRANS' : \"Transportation used\"})"
      ],
      "metadata": {
        "id": "XkpHmGm2WelC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2,figsize = (12,5))\n",
        "plt.suptitle(\"Target Distribution\")\n",
        "\n",
        "sns.histplot(binwidth=0.5,x=TARGET,data=train,hue='Gender',palette=\"dark\",ax=axs[0],discrete=True)\n",
        "axs[0].tick_params(axis='x', rotation=60)\n",
        "\n",
        "axs[1].pie(\n",
        "        train[TARGET].value_counts(),\n",
        "        shadow = True,\n",
        "        explode=[.1 for i in range(train[TARGET].nunique())],\n",
        "        labels = train[TARGET].value_counts().index,\n",
        "        autopct='%1.f%%',\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JcYgLRI9WesN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axs = plt.subplots(len(raw_num_cols),1,figsize=(12,len(raw_num_cols)*2.5),sharex=False)\n",
        "for i, col in enumerate(raw_num_cols):\n",
        "    sns.violinplot(x=TARGET, y=col,hue=\"Gender\", data=train,ax = axs[i], split=False)\n",
        "    if col in full_form.keys():\n",
        "        axs[i].set_ylabel(full_form[col])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CuJhM4hos9Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,axs = plt.subplots(int(len(raw_cat_cols)-1),2,figsize=(12,len(raw_cat_cols)*3),width_ratios=[1, 4])\n",
        "for i,col in enumerate(raw_cat_cols[1:]):\n",
        "    sns.countplot(y=col,data=train,palette=\"bright\",ax=axs[i,0])\n",
        "    sns.countplot(x=col,data=train,hue=TARGET,palette=\"bright\",ax=axs[i,1])\n",
        "    if col in full_form.keys():\n",
        "        axs[i,0].set_ylabel(full_form[col])\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s5T4PFsLtAMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = train[raw_num_cols].corr(\"pearson\")\n",
        "sns.heatmap(tmp,annot=True,cmap =\"crest\")"
      ],
      "metadata": {
        "id": "9-XCM4uCtEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(data=train, x=\"Height\", y=\"Weight\", hue=TARGET,height=6)"
      ],
      "metadata": {
        "id": "ubj9hlCiyjiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(data=train, x=\"Age\", y=\"Height\", hue=TARGET,height=6)"
      ],
      "metadata": {
        "id": "Bh5gn2hPylHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "84530mFbyoTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_top_2 = pca.fit_transform(train[raw_num_cols])\n",
        "\n",
        "tmp = pd.DataFrame(data = pca_top_2, columns = ['pca_1','pca_2'])\n",
        "tmp['TARGET'] = train[TARGET]\n",
        "\n",
        "fig,axs = plt.subplots(2,1,figsize = (12,6))\n",
        "sns.scatterplot(data=tmp, y=\"pca_1\", x=\"pca_2\", hue='TARGET',ax=axs[0])\n",
        "axs[0].set_title(\"Top 2 Principal Components\")\n",
        "\n",
        "#KMeans\n",
        "kmeans = KMeans(7,random_state=RANDOM_SEED)\n",
        "kmeans.fit(tmp[['pca_1','pca_2']])\n",
        "sns.scatterplot( y= tmp['pca_1'],x = tmp['pca_2'],c = kmeans.labels_,cmap='viridis', marker='o', edgecolor='k', s=50, alpha=0.8,ax = axs[1])\n",
        "axs[1].set_title(\"Kmean Clustring on First 2 Principal Components\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qfyQHBH5ynia"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}